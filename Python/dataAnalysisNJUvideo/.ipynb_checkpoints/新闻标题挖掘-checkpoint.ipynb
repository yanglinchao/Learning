{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82301fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from imageio import imread\n",
    "import time\n",
    "from wordcloud import WordCloud\n",
    "import inspect\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abd46a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sina_news():\n",
    "    PATTERN=re.compile('.shtml\"target=\"_blank\">(.*?)</a><span>(.*?)</span></li>')\n",
    "    BASE_URL=\"http://roll.news.sina.com.cn/news/gnxw/gdxwl/index_\"\n",
    "    MAX_PAGE_NUM=5\n",
    "    \n",
    "    with open('subject.txt','w',encoding='utf-8') as f:\n",
    "        for i in range(1, MAX_PAGE_NUM):\n",
    "            print('Downloading page #{}'.format(i))\n",
    "            r=requests.get(BASE_URL+str(i)+'.shtml')\n",
    "            r.encoding='gb2312'\n",
    "            data=r.text\n",
    "            p=re.findall(PATTERN, data)\n",
    "            for s in p:\n",
    "                f.write(s[0])\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09b8ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words():\n",
    "    \n",
    "    with open('subject.txt','r',encoding='utf-8') as f:\n",
    "        news_subjects=f.readlines()\n",
    "        \n",
    "    stop_words=set(line.strip() for line in open('stopwords.txt', encoding='utf-8'))\n",
    "    \n",
    "    newslist=[]\n",
    "    \n",
    "    for subject in news_subjects:\n",
    "        if subject.isspace():\n",
    "            continue\n",
    "        # segment words line by line\n",
    "        word_list=pseg.cut(subject)\n",
    "        for word, flag in word_list:\n",
    "            if not word in stop_words and flag == 'n':\n",
    "                newlist.append(word)\n",
    "    \n",
    "    filename=inspect.getframeinfo(inspect.currentframe()).filename\n",
    "    d=os.path.dirname(os.path.abspath(filename))\n",
    "    mask_image=d+\"\\\\mikey.png\"\n",
    "    \n",
    "    content=''.join(newslist)\n",
    "    wordcloud=WordCloud(font_path='simhei.ttf', background_color=\"grey\", mask=mask_image, max_words=40).generate(content)\n",
    "    \n",
    "    # Display the generated image:\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    wordcloud.to_file('wordcloud.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86b15906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading page #1\n",
      "Downloading page #2\n",
      "Downloading page #3\n",
      "Downloading page #4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "We need at least 1 word to plot a word cloud, got 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-13c994652ab3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mfetch_sina_news\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mextract_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-eb3d75bd24f5>\u001b[0m in \u001b[0;36mextract_words\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewslist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mwordcloud\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'simhei.ttf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackground_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"grey\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# Display the generated image:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \"\"\"\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \"\"\"\n\u001b[0;32m    613\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             raise ValueError(\"We need at least 1 word to plot a word cloud, \"\n\u001b[1;32m--> 404\u001b[1;33m                              \"got %d.\" % len(frequencies))\n\u001b[0m\u001b[0;32m    405\u001b[0m         \u001b[0mfrequencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrequencies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: We need at least 1 word to plot a word cloud, got 0."
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    fetch_sina_news()\n",
    "    extract_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c963c016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ylc\\GitHub\\Learning\\Python\\dataAnalysisNJUvideo\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import os\n",
    "filename = inspect.getframeinfo(inspect.currentframe()).filename\n",
    "path = os.path.dirname(os.path.abspath(filename))\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e432c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
