{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 张量：多维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3) # 创建一个大小为3的一维张量，用1.0填充\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2] = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 索引张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python列表索引\n",
    "some_list = list(range(6))\n",
    "some_list[:] # 列表中所有元素\n",
    "some_list[1:4] # 包含第1个元素到第3个元素，不包含第4个元素\n",
    "some_list[1:] # 包含第1个元素到列表末尾的元素\n",
    "some_list[:4] # 从列表开始到第3各元素，不包含第4个元素\n",
    "some_list[:-1] # 从列表的开始到最后一个元素之前的所有元素\n",
    "some_list[1:4:2] # 从第1个元素（包含）到第4个元素（不包含），移动步长为2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 1.],\n",
       "         [5., 3.],\n",
       "         [2., 1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 张量索引\n",
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points[1:] # 第1行之后的所有行，隐含所有列\n",
    "points[1:, :] # 第1行之后的所有行，所有列\n",
    "points[1:, 0] # 第1行之后的所有行，第1列\n",
    "points[None] # 增加大小为1的维度，就像unsqueeze()方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 命名张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 张量的维度或坐标轴通常用来表示诸如像素位置或颜色通道的信息，这意味着当我们要把一个张量作为索引时，需要记住维度的顺序并按此顺序编写索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t = torch.randn(3, 5, 5) # shape [channels,rows,columns]\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n",
    "\n",
    "batch_t = torch.randn(2, 3, 5, 5) # shape [batch,channels,rows,columns]\n",
    "\n",
    "# RGB通道总在从末端开始的第3维。所以惰性的未加权平均值可以写成：\n",
    "img_gray_navie = img_t.mean(-3) # 在倒数第3维上求均值\n",
    "batch_gray_navie = batch_t.mean(-3) # 在倒数第3维上求均值\n",
    "img_gray_navie.shape, batch_gray_navie.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> PyTorch将允许对相同形状的张量进行乘法运算，也允许与给定维度中其中一个操作数大小为1的张量进行运算。它还会自动附加大小为1的前导维度，这个特性被称为广播<br> 形状为(2,3,5,5)的batch_t乘一个形状为(3,1,1)unsqueezed_weights张量，得到一个形状为(2,3,5,5)的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1) # 增加维度，使weights由[3]变为[3,1,1]\n",
    "img_weights = (img_t * unsqueezed_weights) # img_t是[3,5,5]\n",
    "batch_weights = (batch_t * unsqueezed_weights) # batch_t是[2,3,5,5]\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 命名张量是一个试验性的特性。张量工厂函数（诸如tensor()和rand()函数）有一个names参数，该参数是一个字符串序列<br> 当已经有一个张量并且想要为其添加名称但不改变现有的名称时，可以对其调用refine_names()方法<br> 与索引类似，省略号（...）允许省略任意数量的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-18dfef1583c2>:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\c10/core/TensorImpl.h:1463.)\n",
      "  weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n"
     ]
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "batch named: torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "print(\"img named:\", img_named.shape, img_named.names)\n",
    "print(\"batch named:\", batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> align_as()方法返回一个张量，其中添加了缺失的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3288,  0.5182, -0.1372, -0.1133,  1.3232],\n",
       "         [ 0.1769, -0.6114, -0.1858, -0.4913, -1.0995],\n",
       "         [-0.9871,  0.2338,  0.5339, -0.4538,  0.7615],\n",
       "         [ 0.2828, -0.5871,  1.1352,  1.1719,  2.1611],\n",
       "         [ 0.2247,  1.1713,  0.4192, -0.0594, -0.4336]],\n",
       "\n",
       "        [[ 0.5314,  1.3407,  0.9194,  0.1881,  0.0520],\n",
       "         [-1.3833, -1.1005, -1.8879, -0.4862,  1.3897],\n",
       "         [ 1.1135,  2.0742, -0.4646,  0.5100, -0.2030],\n",
       "         [ 0.6632,  0.3951, -0.2613, -0.1183,  0.5028],\n",
       "         [-0.7822,  1.7327,  0.7137, -0.5928, -0.7704]],\n",
       "\n",
       "        [[ 0.4322,  0.5245,  0.5777, -0.6532, -0.6770],\n",
       "         [-0.9522, -0.8489, -0.8848,  0.0692,  0.1155],\n",
       "         [ 0.8614,  0.6715, -1.6090,  1.6301, -1.3214],\n",
       "         [ 2.8653, -1.5783, -0.1659, -0.6980, -0.3391],\n",
       "         [-0.3951, -0.2601,  0.4095,  0.4812,  0.5965]]],\n",
       "       names=('channels', 'rows', 'columns'))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 1]) \n",
      "  tensor([[[0.2126]],\n",
      "\n",
      "        [[0.7152]],\n",
      "\n",
      "        [[0.0722]]], names=('channels', 'rows', 'columns'))\n"
     ]
    }
   ],
   "source": [
    "weights_aligned = weights_named.align_as(img_named)\n",
    "print(weights_aligned.shape,\"\\n\", weights_aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 接收维度参数的函数，例如sum()，也接收命名维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'columns'))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named = (img_named * weights_aligned).sum('channels')\n",
    "gray_named.shape, gray_named.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">如果用不同的名称组合维度，会出现错误"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在对命名的张量进行操作的函数之外使用张量，需要通过将这些张量重命名为None来删除它们的名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), (None, None))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_plain = gray_named.rename(None)\n",
    "gray_plain.shape, gray_plain.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 张量的元素类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int16"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)\n",
    "short_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]], dtype=torch.float64),\n",
       " tensor([[1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1]], dtype=torch.int16))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换类型\n",
    "double_points = torch.zeros(10, 2).double()\n",
    "short_points = torch.ones(10, 2).short()\n",
    "double_points, short_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> to()方法会检查转换是否是必要的，如果必要，则执行转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points = torch.zeros(10, 2).to(torch.double)\n",
    "double_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 张量元数据：大小、偏移量和步长"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.1 偏移量、步长、复制等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1]\n",
    "second_point.storage_offset() # 张量在储存区中的偏移量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 张量在存储区中的偏移量为2，是因为需要跳过第1个点（[4.0, 1.0]），该点共有两个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), torch.Size([2]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.size(), second_point.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> size()是Size类的一个实例，因为该张量是一维的，所以包含一个元素。函数size()所包含的信息与张量对象的shape属性所包含的相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 步长是一个元组，指示当索引在每个维度中增加1时在存储区中必须跳过的元素数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride() # 查看步长"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 访问一个二维张良中的位置(i,j)的元素会导致访问储存中的第storage_offset+stride[0]*i_stride[1]*j个元素。偏移量通常为0，如果这个张量是为容纳更大的张量而创建的存储视图，那么偏移量可以为正值<br> 这种张量和存储区之间的间接关系使得一些操作开销并不大，如转置一个张量或者提取一个子张量，因为它们不会导致内存重新分配，而是创建一个新的张量对象，该张量具有不同的大小偏移量和步长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point = points[1]\n",
    "second_point.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 子张量的维度少了一维，同时仍然索引了与原始张量points相同的存储区，意味着更改子张量会对原始张量产生影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 可以把子张量复制成一个新的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1].clone()\n",
    "second_point[0] = 10.0\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.2 无复制转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t = points.t() # 转置，transpose()方法的简写\n",
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(points.storage()) == id(points_t.storage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ??这里不应该是True?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.3 高维转置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> PyTorch中的转置不限于矩阵。可以通过指定2个维度，即翻转形状和步长，来转置一个多维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4, 5]), torch.Size([5, 4, 3]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t = torch.ones(3, 4, 5)\n",
    "transpose_t = some_t.transpose(0, 2)\n",
    "some_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 3])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 20)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.4 连续张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在PyTorch中一些张量操作只对连续张量起作用，利用contiguous()方法，可以通过一个非连续张量得到一个新的连续张量，张量的内容是一样的，但是步长和存储发生了改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont = points_t.contiguous()\n",
    "points_t_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 5.0\n",
       " 2.0\n",
       " 1.0\n",
       " 3.0\n",
       " 1.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 将张量储存到GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 可以用指定构造函数或to()方法在GPU上创建张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points_gpu = points.to(divice='cuda:0') # 如果有多个GPU，可以从0开始传递一个整数来确定存储张量的GPU 但是我没有"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在此基础上，对张量的任何操作都将在GPU上执行，不会返回到CPU，可以通过向to()提供一个CPU参数，将张量移回CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.,  2.],\n",
       "        [10.,  6.],\n",
       "        [ 4.,  2.]], device='cuda:0')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu = 2 * points.to(device='cuda') # 在GPU上执行乘法\n",
    "points_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.,  2.],\n",
       "        [10.,  6.],\n",
       "        [ 4.,  2.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu = points_gpu.to(device='cpu') # 移回CPU\n",
    "points_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过简写的cpu()和cuda()替代to()\n",
    "points_gpu = points.cuda()\n",
    "points_gpu = points.cuda(0)\n",
    "points_gpu = points_gpu.cpu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
